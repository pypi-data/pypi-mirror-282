Metadata-Version: 2.1
Name: quantile-tree
Version: 0.0.1
Summary: Monotone quantile regressor
Home-page: https://github.com/RektPunk/monotone-quantile-tree
Author: RektPunk
Author-email: rektpunk@gmail.com
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.6
Description-Content-Type: text/markdown
Requires-Dist: numpy >=2.0.0
Requires-Dist: pandas >=2.0.0
Requires-Dist: lightgbm >=4.0.0
Requires-Dist: xgboost >=2.0.0

# About

Multiple quantiles estimation model maintaining non-crossing condition (or monotone quantile condition) using Lightgbm and XGBoost

# Getting Started
1. Install
```bash
pip install quantile-tree
```

2. Run example code
```python
import numpy as np
import plotly.graph_objects as go
from quantile_tree import QuantileRegressorLgb, QuantileRegressorXgb


if __name__ == "__main__":
    sample_size = 500
    alphas = [0.3, 0.4, 0.5, 0.6, 0.7]
    x = np.linspace(-10, 10, sample_size)
    y = np.sin(x) + np.random.uniform(-0.4, 0.4, sample_size)
    x_test = np.linspace(-10, 10, sample_size)
    y_test = np.sin(x_test) + np.random.uniform(-0.4, 0.4, sample_size)

    monotonic_quantile_lgb = QuantileRegressorLgb(x=x, y=y_test, alphas=alphas)
    lgb_params = {
        "max_depth": 4,
        "num_leaves": 15,
        "learning_rate": 0.1,
        "boosting_type": "gbdt",
    }
    monotonic_quantile_lgb.train(params=lgb_params)
    preds_lgb = monotonic_quantile_lgb.predict(x=x_test, alphas=alphas)

    lgb_fig = go.Figure(
        go.Scatter(
            x=x_test,
            y=y_test,
            name="test",
            mode="markers",
        )
    )
    for _pred, alpha in zip(preds_lgb, alphas):
        lgb_fig.add_trace(
            go.Scatter(x=x_test, y=_pred, name=f"{alpha}-quantile", mode="lines")
        )

    lgb_fig.update_layout(title="LightGBM Predictions")
    lgb_fig.show()

    monotonic_quantile_xgb = QuantileRegressorXgb(x=x, y=y_test, alphas=alphas)
    params = {
        "learning_rate": 0.65,
        "max_depth": 10,
    }
    monotonic_quantile_xgb.train(params=params)
    preds_xgb = monotonic_quantile_xgb.predict(x=x_test, alphas=alphas)

    xgb_fig = go.Figure(
        go.Scatter(
            x=x_test,
            y=y_test,
            name="test",
            mode="markers",
        )
    )
    for _pred, alpha in zip(preds_xgb, alphas):
        xgb_fig.add_trace(
            go.Scatter(x=x_test, y=_pred, name=f"{alpha}-quantile", mode="lines")
        )

    xgb_fig.update_layout(title="XGBoost Predictions")
    xgb_fig.show()
```
3. Results
![](img/lightgbm.png)
![](img/xgboost.png)

4. Structure
```
.
├── quantile_tree
│   ├── __init__.py
│   ├── abstract.py  # abstract quantile tree
│   ├── model.py     # seperate train logic
│   ├── objective.py # objective ftns
│   └── utils.py     # utils such as verify quantiles and preprocessing
```
