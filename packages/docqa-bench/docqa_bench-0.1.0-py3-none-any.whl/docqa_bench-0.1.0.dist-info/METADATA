Metadata-Version: 2.1
Name: docqa-bench
Version: 0.1.0
Summary: A library for benchmarking document QA systems
Home-page: https://github.com/JoshuaOliphant/docqa_bench
License: MIT
Author: Joshua Oliphant
Author-email: joshua.oliphant@hey.com
Requires-Python: >=3.8,<4.0
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Requires-Dist: chromadb (>=0.3.0,<0.4.0)
Requires-Dist: langchain (>=0.0.150,<0.0.151)
Requires-Dist: openai (>=0.27.0,<0.28.0)
Requires-Dist: pypdf (>=3.0.0,<4.0.0)
Requires-Dist: scikit-learn (>=1.0.2,<2.0.0)
Project-URL: Repository, https://github.com/JoshuaOliphant/docqa_bench
Description-Content-Type: text/markdown

# DocQA-Bench

DocQA-Bench is a library for benchmarking document question-answering systems.

## Installation

You can install DocQA-Bench using pip:
`pip install docqa-bench`

## Quick Start

Check out the `example.py` file in the root directory for a demonstration of how to use `docqa_bench`. This example shows how to:

1. Set up the necessary components
2. Create a benchmark
3. Run the benchmark on preprocessed content
4. Handle and display the results

To run the example:

```bash
python example.py
