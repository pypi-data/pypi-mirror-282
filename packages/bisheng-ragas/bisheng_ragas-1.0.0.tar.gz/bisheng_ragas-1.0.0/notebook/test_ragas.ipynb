{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "082aec1e-08ac-4021-a969-b38afde1f718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# url = \"https://raw.githubusercontent.com/langchain-ai/langchain/master/docs/docs/modules/state_of_the_union.txt\"\n",
    "# res = requests.get(url)\n",
    "# with open(\"state_of_the_union.txt\", \"w\") as f:\n",
    "#     f.write(res.text)\n",
    "\n",
    "# Load the data\n",
    "loader = TextLoader('./state_of_the_union.txt')\n",
    "documents = loader.load()\n",
    "\n",
    "# Chunk the data\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f7667af-3949-4a34-aa47-a396b5cdc962",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Milvus\n",
    "import httpx\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\", \n",
    "                              openai_api_key='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', \n",
    "                              openai_proxy='http://118.195.232.223:39995',\n",
    "                              http_client=httpx.Client(proxies='http://118.195.232.223:39995'))\n",
    "\n",
    "MILVUS_HOST = '192.168.106.116'\n",
    "MILVUS_PORT = '19530'\n",
    "vector_store = Milvus.from_documents(\n",
    "    chunks,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"state_of_the_union_embedding\",\n",
    "    drop_old=True,\n",
    "    connection_args={\"host\": MILVUS_HOST, \"port\": MILVUS_PORT}\n",
    ")\n",
    "vector_retriever = vector_store.as_retriever(search_type=\"similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc8bd09-dfd8-4652-9c36-136062545712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea6bdfc6-1cc7-4749-8a02-2a1ad0403d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "# Define LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, \n",
    "                 openai_api_key='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', \n",
    "                 http_client=httpx.Client(proxies='http://118.195.232.223:39995'))\n",
    "\n",
    "# Define prompt template\n",
    "template = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use two sentences maximum and keep the answer concise.\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Setup RAG pipeline\n",
    "rag_chain = (\n",
    "    {\"context\": vector_retriever,  \"question\": RunnablePassthrough()} \n",
    "    | prompt \n",
    "    | llm\n",
    "    | StrOutputParser() \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7f0cac7-6653-4046-a541-c635044fa751",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "questions = [\"What did the president say about Justice Breyer?\", \n",
    "             \"What did the president say about Intel's CEO?\",\n",
    "             \"What did the president say about gun violence?\",\n",
    "            ]\n",
    "ground_truths = [[\"The president said that Justice Breyer has dedicated his life to serve the country and thanked him for his service.\"],\n",
    "                [\"The president said that Pat Gelsinger is ready to increase Intel's investment to $100 billion.\"],\n",
    "                [\"The president asked Congress to pass proven measures to reduce gun violence.\"]]\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "# Inference\n",
    "for query in questions:\n",
    "  answers.append(rag_chain.invoke(query))\n",
    "  contexts.append([docs.page_content for docs in vector_retriever.get_relevant_documents(query)])\n",
    "\n",
    "# To dict\n",
    "data = {\n",
    "    \"question\": questions,\n",
    "    \"answer\": answers,\n",
    "    \"contexts\": contexts,\n",
    "    \"ground_truths\": ground_truths\n",
    "}\n",
    "\n",
    "# Convert dict to dataset\n",
    "dataset = Dataset.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b7b24fc-dff6-469b-993b-8ec8f4273b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_precision]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_recall]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [faithfulness]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_relevancy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.13s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "os.environ[\"OPENAI_PROXY\"] = \"http://118.195.232.223:39995\"\n",
    "from bisheng_ragas import evaluate\n",
    "from bisheng_ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "\n",
    "result = evaluate(\n",
    "    dataset = dataset, \n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        context_recall,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "    ],\n",
    ")\n",
    "\n",
    "df = result.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b7ebf88-0cb9-45c2-ab9d-9ba5f3d11270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truths</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What did the president say about Justice Breyer?</td>\n",
       "      <td>The president thanked Justice Breyer for his s...</td>\n",
       "      <td>[Tonight, I’d like to honor someone who has de...</td>\n",
       "      <td>[The president said that Justice Breyer has de...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.894318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What did the president say about Intel's CEO?</td>\n",
       "      <td>The president did not mention Intel's CEO in t...</td>\n",
       "      <td>[But that’s just the beginning. \\n\\nIntel’s CE...</td>\n",
       "      <td>[The president said that Pat Gelsinger is read...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.959788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What did the president say about gun violence?</td>\n",
       "      <td>The president called for Congress to pass meas...</td>\n",
       "      <td>[And I ask Congress to pass proven measures to...</td>\n",
       "      <td>[The president asked Congress to pass proven m...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question  \\\n",
       "0  What did the president say about Justice Breyer?   \n",
       "1     What did the president say about Intel's CEO?   \n",
       "2    What did the president say about gun violence?   \n",
       "\n",
       "                                              answer  \\\n",
       "0  The president thanked Justice Breyer for his s...   \n",
       "1  The president did not mention Intel's CEO in t...   \n",
       "2  The president called for Congress to pass meas...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [Tonight, I’d like to honor someone who has de...   \n",
       "1  [But that’s just the beginning. \\n\\nIntel’s CE...   \n",
       "2  [And I ask Congress to pass proven measures to...   \n",
       "\n",
       "                                       ground_truths  context_precision  \\\n",
       "0  [The president said that Justice Breyer has de...               1.00   \n",
       "1  [The president said that Pat Gelsinger is read...               1.00   \n",
       "2  [The president asked Congress to pass proven m...               0.75   \n",
       "\n",
       "   context_recall  faithfulness  answer_relevancy  \n",
       "0             1.0           1.0          0.894318  \n",
       "1             1.0           NaN          0.959788  \n",
       "2             1.0           1.0          0.909126  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7c81ea4-8c2b-489f-8397-cb4b8b642255",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"test_state_of_the_union.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aac355-dce8-4acd-8c45-49a92069e17a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e35174f-d42d-4252-af25-d30da8d61f00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33030b17-03e0-4f11-b821-986d867799cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
