# MLOps 프로젝트

![](figs/MLOps-project.jpeg)

**MLOps 팀 프로젝트: 베어메탈부터 시작하는 엔드-투-엔드 머신러닝 파이프라인**

## 목표

이 프로젝트는 학생들에게 베어메탈 시스템에서부터 엔드-투-엔드 머신러닝 파이프라인을 구축하는 과정을 가르치는 것을 목표로 합니다. 프로젝트는 운영 체제 설정, 머신러닝 프레임워크 구성 및 머신러닝 모델 학습을 다룰 것입니다. 최종 결과물은 GitHub 저장소를 통해 클래스와 공유될 것입니다.

## 요구사항

- Linux 운영 체제에 대한 기본 지식
- 머신러닝 개념 및 프레임워크에 대한 이해
- 버전 관리 및 협업을 위한 Git 및 GitHub
- 컨테이너화 및 오케스트레이션을 위한 Docker 및 Kubernetes 경험 (선택 사항이지만 권장됨)

## 프로젝트 개요

### 1. 프로젝트 기획 및 팀 구성

- 프로젝트 범위 및 목표 정의
- 클래스를 하위 팀으로 나누기: OS 설정, ML 프레임워크 설정, 모델 개발 및 MLOps 설정
- 프로젝트 관리 도구(예: Trello) 설정하여 진행 상황 추적 및 작업 할당

### 2. 운영 체제 설정

- Linux 배포판 선택(예: Ubuntu, CentOS)
- 베어메탈 서버에 운영 체제 설치 및 구성
- 사용자 계정 및 권한 설정
- 필수 도구 설치 및 구성(예: SSH, Git)

### 3. 머신러닝 프레임워크 설정

- ML 프레임워크 선택(예: TensorFlow, PyTorch)
- 서버에 ML 프레임워크 설치 및 구성
- 종속성 및 라이브러리 설정
- 샘플 ML 모델로 프레임워크 테스트

### 4. 모델 개발

- 문제 및 데이터셋 선택(예: 이미지 분류, 감성 분석)
- 데이터 전처리 및 특성 엔지니어링 수행
- 모델 학습 및 평가
- 하이퍼파라미터 최적화를 통한 모델 미세 조정

### 5. MLOps 설정

- Docker를 사용하여 ML 모델 컨테이너화
- Jenkins 또는 GitHub Actions와 같은 도구를 사용하여 CI/CD 파이프라인 설정
- Kubernetes 클러스터에 모델 배포(선택 사항)
- 모델 성능 모니터링 및 관련 메트릭 로깅
- 자동화된 테스트 및 검증 구현

### 6. 최종 마무리 및 문서화

- 각 하위 팀의 작업 통합
- 설치 가이드, 모델 개발 및 배포를 포함한 프로젝트에 대한 포괄적인 문서 작성
- GitHub에 최종 프로젝트 공유, 모든 팀원이 저장소에 기여했는지 확인
- 주요 단계, 과제 및 결과를 강조하는 클래스 프로젝트 발표 준비

## 결과

- 학생들은 엔드-투-엔드 머신러닝 파이프라인 설정에 대한 실습 경험을 쌓을 수 있습니다.
- 학생들은 팀원 간에 효과적으로 협업하고 작업을 분담하는 방법을 배울 것입니다.
- 학생들은 MLOps에서 버전 관리 및 문서화의 중요성을 이해하게 될 것입니다.
- 최종 GitHub 저장소는 클래스 및 미래 학생들을 위한 리소스 역할을 할 것입니다.

```{tableofcontents}

```
