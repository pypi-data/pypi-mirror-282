# RAG í”„ë¡œì íŠ¸ - ì œì£¼ ì—­ì‚¬ ê´€ê´‘ì§€ ê°€ì´ë“œ llm

## RAG í”„ë¡œê·¸ë¨ êµ¬í˜„ê³¼ì •

ìˆœì„œ : ê¸°ì´ˆ ì„¤ëª… - êµ¬í˜„ ë‚´ìš©&ì½”ë“œ - ê²°ê³¼ - ê³ ì°°

### 1. RAG Basic

RAGëŠ” ê²€ìƒ‰ ì¦ê°• ìƒì„±ì˜ ì•½ìë¡œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ ì¶œë ¥ì„ ìµœì í™”í•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•˜ê¸° ì „ í•™ìŠµ ë°ì´í„° ì†ŒìŠ¤ ì™¸ë¶€ì˜ ì‹ ë¢° í•  ìˆ˜ ìˆëŠ” ì§€ì‹ ë² ì´ìŠ¤ë¥¼ ì°¸ì¡°í•˜ë„ë¡ í•˜ëŠ” í”„ë¡œì„¸ìŠ¤ì´ë‹¤.

![RAGêµ¬ì¡°](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTdh_T-gI0N4GDChzqjVl7AsgcWWMttEM7ISg&s)

RAGì˜ êµ¬í˜„ì„ ìœ„í•´ì„œëŠ” Indexing ê³¼ì •ê³¼ Retrieval and Generationì˜ ë‘ ê³¼ì •ì„ ê±°ì¹œë‹¤.

### 2. Indexing

Indexingì€ ì™¸ë¶€ë°ì´í„° ìƒì„±ìœ¼ë¡œ ì›ë˜ LLM ì™¸ë¶€ì— ìˆëŠ” ìƒˆ ë°ì´í„°ë¥¼ ì™¸ë¶€ ë°ì´í„°ë¼ê³  í•œë‹¤. ì´ë¥¼ ìƒì„±í˜• aiëª¨ë¸ì´ ì´í•´ í•  ìˆ˜ ìˆë„ë¡ ì§€ì‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ìƒì„±í•˜ëŠ” ê³¼ì •ì´ Indexingì´ë‹¤.

- APIë‚˜ ë°ì´í„°ë² ì´ìŠ¤, ë¬¸ì„œì™€ ê°™ì€ ì—¬ëŸ¬ ë°ì´í„° ì†ŒìŠ¤ì—ì„œ ì¶”ì¶œ ê°€ëŠ¥
- ë°ì´í„°ë¥¼ ìˆ˜ì¹˜ë¡œ ë³€í™˜í•˜ê³  ë²¡í„° ë°ì´í„° ë² ì´ìŠ¤ì— ì €ì¥ / ë²¡í„° ë°ì´í„° ë² ì´ìŠ¤ = ìƒì„±í˜• aiëª¨ë¸ì´ ì´í•´ í•  ìˆ˜ ìˆëŠ” ì§€ì‹ ë¼ì´ë¸ŒëŸ¬ë¦¬

ì¦‰, ì†ŒìŠ¤ë¡œ ë¶€í„° ë°ì´í„°ë¥¼ ëª¨ì•„ vectorstoreë¥¼ êµ¬ì¶•í•˜ëŠ” íŒŒì´í”„ë¼ì¸ì´ë‹¤.

![IndexingPipline](https://velog.velcdn.com/images/jjlee6496/post/f4443dd4-cdca-4e4c-83e6-8ec515c21db5/image.png)

ê° ê³¼ì •ì—ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì¼ì„ ì§„í–‰í•œë‹¤.

#### Load : pdf, Html, txt ì—¬ëŸ¬ í˜•íƒœì˜ ì†ŒìŠ¤ë“¤ì„ loaderì„ í†µí•´ ë¶ˆëŸ¬ì˜¤ê³  ì²˜ë¦¬

#### Split : splitterì„ ì´ìš©í•´ ìœ„ì—ì„œ ë¶ˆëŸ¬ì˜¨ ë¬¸ì„œë¥¼ ì²˜ë¦¬ ê°€ëŠ¥í•œ ì‘ì€ ë‹¨ìœ„ë¡œ ë¶„í• 

#### Embed :ê° ë¬¸ì„œ ë˜ëŠ” ë¬¸ì„œì˜ ì¼ë¶€ë¥¼ ë²¡í„° í˜•íƒœë¡œ ë³€í™˜í•˜ì—¬, ë¬¸ì„œì˜ ì˜ë¯¸ë¥¼ ìˆ˜ì¹˜í™”

- ì´ëŠ” ì±…ì˜ ë‚´ìš©ì„ ìš”ì•½í•˜ì—¬ í•µì‹¬ í‚¤ì›Œë“œë¡œ í‘œí˜„í•˜ëŠ” ê²ƒê³¼ ë¹„ìŠ·í•˜ë‹¤.

#### store : ì„ë² ë”©ëœ ë²¡í„°ë“¤ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥

- ìš”ì•½ëœ í‚¤ì›Œë“œë¥¼ ìƒ‰ì¸í™”í•˜ì—¬ ë‚˜ì¤‘ì— ë¹ ë¥´ê²Œ ì°¾ì„ ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ê³¼ì •ì´ë‹¤.

### 3. Retrieval and Generation

![RAGêµ¬ì¡°](https://velog.velcdn.com/images/jjlee6496/post/15b30fe5-1015-47b4-b837-d692f9a101fd/image.png)

#### Retrieval: ê¸°ì¡´ ì •ë³´ ê²€ìƒ‰ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•˜ì—¬ target informationì— ëŒ€í•œ ë¬¸ì„œ ë˜ëŠ” ì •ë³´ë¥¼ ê²€ìƒ‰

#### Generator: Retrieverê°€ ê²€ìƒ‰í•œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì˜ë¯¸ìˆëŠ” ë¬¸ì¥ ë˜ëŠ” ë¬¸ë‹¨ ìƒì„±

ì´ë¥¼ í†µí•´ RAGëŠ” LLMì˜ ê¸°ë³¸ ëª¨ë¸ ìì²´ë¥¼ ìˆ˜ì •í•˜ì§€ ì•Šê³ ë„ ìµœì‹  ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•  ìˆ˜ ìˆê²Œ ëœë‹¤.

## Indexing

### 1. DATA

ì£¼ì œì— ë§ëŠ” ì†ŒìŠ¤ë¥¼ ì°¾ê³  í¸ì˜ë¥¼ ìœ„í•´ pdfë¡œ ì €ì¥í–ˆë‹¤.
ë°ì´í„° ëª©ë¡

```
'ê°€ìŠ´ ì•„í”ˆ ì œì£¼ ì—­ì‚¬ë¥¼ ëŒì•„ë³´ëŠ” ë‹¤í¬íˆ¬ì–´ ì—¬í–‰ì§€ _ ì§€ì‹ë°±ê³¼.pdf'
'ì—­ì‚¬ ë¬¸í™”ì˜ ìˆ¨ê²°ì„ ì°¾ì•„ì„œ, ì œì£¼ ì›ë„ì‹¬ ì—¬í–‰ _ ì§€ì‹ë°±ê³¼.pdf'
'ì œì£¼ ë¹Œë ˆëª» ë™êµ´ _ ì§€ì‹ë°±ê³¼.pdf'
'ì œì£¼ë„ í‘œë¥˜ì˜ ì—­ì‚¬ _ ì§€ì‹ë°±ê³¼.pdf'
'ì œì£¼ë„ì˜ ì—­ì‚¬ê°€ ì‹œì‘ëœ ì‚¼ì„±í˜ˆ _ ì§€ì‹ë°±ê³¼.pdf'
'ì œì£¼ì˜ ì•„í”ˆ ì—­ì‚¬ ëŒì•„ë³´ëŠ” ë‹¤í¬íˆ¬ì–´ë¦¬ì¦˜, 8.15ë¥¼ í†µí•´ ë³´ëŠ” ì œì£¼ í•­ì¼ ì—­ì‚¬ì˜ ë°œìì·¨ _ ì§€ì‹ë°±ê³¼.pdf'
'ì œì£¼ì¸ í•­ì¼ìš´ë™ ì—­ì‚¬ì˜ ë³´ê³ (å¯¶åº«) _ì œì£¼í•­ì¼ê¸°ë…ê´€_ _ ì§€ì‹ë°±ê³¼.pdf'
'ì œì£¼ì „ìŸì—­ì‚¬í‰í™”ë°•ë¬¼ê´€ _ ì§€ì‹ë°±ê³¼.pdf'
```

### 2. vectorstore êµ¬ì¶•

chromadbì™€ langchainì„ í†µí•´ ì•ì— ë‚˜ì˜¨ íŒŒì´í”„ë¼ì¸ì„ í†µí•´ vectorstore êµ¬ì¶•í–ˆë‹¤.

```python
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import PyPDFDirectoryLoader
from langchain_chroma import Chroma
from langchain_community.embeddings import OllamaEmbeddings

DATA_PATH = "/home/eunjikim22/rag_project/data"
DB_PATH = "/home/eunjikim22/rag_project/vectorstores/db/"


def create_vector_db():
    # ë¶€ë¥´ê³  pdf ê°¯ìˆ˜ ë°˜í™˜
    loader = PyPDFDirectoryLoader(DATA_PATH)
    documents = loader.load()
    print(f"Processed {len(documents)} pdf files")

    # í…ìŠ¤íŠ¸ ë¶„í•  ë¬¸ì„œ ë‹¨ìœ„ë¡œ ìë¦„
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)
    texts = text_splitter.split_documents(documents)
    print("split complete")

    # ì¸ë±ì‹± ë¶„í• ëœ ë¬¸ì„œë¥¼ ê²€ìƒ‰ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë§Œë“¬
    vectorstore = Chroma.from_documents(documents= texts,
                                        embedding=OllamaEmbeddings(model="llama3ko"), persist_directory=DB_PATH)

if __name__ == "__main__":
    create_vector_db()
```

*PyPDFDirectoryLoader*ì™€ *load*í•¨ìˆ˜ë¥¼ í†µí•´ pdfíŒŒì¼ì„ ë¶ˆëŸ¬ì˜¤ê³  ì´ë¥¼ *RecursiveCharacterTextSplitter*ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ë¶„í• í•˜ê³  *text_splitter.split_documents*ì„ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œë‹¨ìœ„ë¡œ ìë¥¸ë‹¤.
ì´ë¥¼ *Chroma.from_documents*í•¨ìˆ˜ë¥¼ í†µí•´ ë¶„í• ëœ ë¬¸ì„œë¥¼ ê²€ìƒ‰ ê°€ëŠ¥í•œ í˜•íƒœë¡œ êµ¬ì¶•í•œë‹¤.

- embeddingìœ¼ë¡œ OllamaEmbeddingsì„ ì‚¬ìš©í–ˆìœ¼ë©° ëª¨ë¸ì€ ì±—ë´‡ êµ¬í˜„ì— ì‚¬ìš©í•  huggingfaceëª¨ë¸ì¸ Llama-3-Open-Ko-8B(=llama3ko)ë¥¼ ì‚¬ìš©í•˜ì˜€ë‹¤.

## RAG êµ¬ì¶•

langchainì˜ ë°ëª¨ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°„ë‹¨í•˜ê²Œ êµ¬ì¶•ì„ ì§„í–‰í–ˆë‹¤.
[ì°¸ê³ í˜ì´ì§€](https://python.langchain.com/v0.2/docs/tutorials/qa_chat_history/)ì—ì„œ promptë¥¼ ì˜ì–´ì—ì„œ í•œêµ­ì–´ë¡œ ë°”ê¾¸ì–´ ì§„í–‰í•˜ì˜€ê³  ì¶”í›„ ì±—ë´‡ êµ¬ì¶•ì„ ìœ„í•´ ìˆ˜ì •í•˜ì—¬ ì§„í–‰í•˜ì˜€ë‹¤.

```python
from langchain_community.chat_models import ChatOllama
from langchain_chroma import Chroma
from langchain_community.embeddings import OllamaEmbeddings
from langchain.chains import create_retrieval_chain
from langchain_core.prompts import ChatPromptTemplate
from langchain.chains.combine_documents import create_stuff_documents_chain

from langchain.chains import create_history_aware_retriever
from langchain_core.prompts import MessagesPlaceholder
from langchain_core.messages import AIMessage, HumanMessage
import time

ollama = ChatOllama(model="llama3ko")

DB_PATH = "/home/eunjikim22/rag_project/vectorstores/db"
vectorstore = Chroma(persist_directory=DB_PATH,
                     embedding_function=OllamaEmbeddings(model='llama3ko'))
retriever = vectorstore.as_retriever()

system_prompt = (
    "ë‹¹ì‹ ì€ Q&A ì‘ì—…ì˜ ë³´ì¡°ìì…ë‹ˆë‹¤."
    "ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ì˜ ë‹¤ìŒ ë¶€ë¶„ì„ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— ëŒ€ë‹µí•˜ì‹­ì‹œì˜¤. "
    "ì§ˆë¬¸. ë‹µì„ ëª¨ë¥´ë©´ ì´ë ‡ê²Œ ë§í•˜ì„¸ìš” "
    "ëª¨ë¥´ê² ìŠµë‹ˆë‹¤. ìµœëŒ€ 3ê°œì˜ ë¬¸ì¥ì„ ì‚¬ìš©í•˜ì„¸ìš”."
    "ê°„ê²°í•˜ê²Œ ëŒ€ë‹µí•˜ì„¸ìš”."
    "\n\n"
    "{context}"
)

contextualize_q_system_prompt = (
    "ì±„íŒ… ê¸°ë¡ ë° ìµœê·¼ ì‚¬ìš©ì ì§ˆë¬¸ ì œê³µ"
    "ì±„íŒ… ê¸°ë¡ì˜ ë§¥ë½ì„ ì°¸ì¡°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    "ì´í•´í•  ìˆ˜ ìˆëŠ” ë…ë¦½í˜• ì§ˆë¬¸ì„ ê³µì‹í™”í•˜ì„¸ìš”."
    "ì±„íŒ… ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤. ì§ˆë¬¸ì— ëŒ€ë‹µí•˜ì§€ ë§ˆì„¸ìš”."
    "í•„ìš”í•˜ë‹¤ë©´ ë‹¤ì‹œ êµ¬ì„±í•˜ê³  ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜í•˜ì„¸ìš”."
)

contextualize_q_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", contextualize_q_system_prompt),
        MessagesPlaceholder("chat_history"),
        ("human", "{input}"),
    ]
)

history_aware_retriever = create_history_aware_retriever(
    ollama, retriever, contextualize_q_prompt
)

qa_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", system_prompt),
        MessagesPlaceholder("chat_history"),
        ("human", "{input}"),
    ]
)

question_answer_chain = create_stuff_documents_chain(ollama, qa_prompt)
rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)

chat_history = []
start = time.time()
question = "ì œì£¼ ë‹¤í¬ íˆ¬ì–´ë¦¬ì¦˜ ê´€ê´‘ì§€ í•œê°€ì§€ ì¶”ì²œí•´ì¤˜"
ai_msg_1 = rag_chain.invoke({"input": question, "chat_history": chat_history})
chat_history.extend(
    [
        HumanMessage(content=question),
        AIMessage(content=ai_msg_1["answer"]),
    ]
)
print(ai_msg_1["answer"])

second_question = "ê·¸ì— ì–½íŒ ì—­ì‚¬ì  ì‚¬ì‹¤ë„ ì•Œë ¤ì¤˜"
ai_msg_2 = rag_chain.invoke({"input": second_question, "chat_history": chat_history})

print(ai_msg_2["answer"])

end = time.time()
print(f'{end-start:.5f}sec')
```

invokeí•œ ê²°ê³¼ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.

```
question = "ì œì£¼ ë‹¤í¬ íˆ¬ì–´ë¦¬ì¦˜ ê´€ê´‘ì§€ í•œê°€ì§€ ì¶”ì²œí•´ì¤˜"

ë„¤, ì œì£¼ë„ì— ìˆëŠ” ì‚¼ì„±í˜ˆì´ìš”. ì´ê³³ì€ ì‚¼ì„ ì‹¬ì—ˆë‹¤ëŠ” ëœ»ìœ¼ë¡œ, ì‹ í™” ì†ì˜ ì„¸ ì„ë¼ê°€ íƒœì–´ë‚˜ê³  ì„±ì¥í•œ ê³³ì…ë‹ˆë‹¤. ê·¸ ì£¼ë³€ì—ëŠ” ì‘ì€ ë¹„ì„ë“¤ì´ ì„œ ìˆê³ , ê·¸ ì˜†ì—ëŠ” ì‚¼ì„±ì „ì´ ìˆìŠµë‹ˆë‹¤
```

```
second_question = "ê·¸ì— ì–½íŒ ì—­ì‚¬ì  ì‚¬ì‹¤ë„ ì•Œë ¤ì¤˜"

ë„¤, ì´ê³³ì€ ì œì£¼ë„ì˜ ê±´êµ­ ì‹ í™”ê°€ ì‹œì‘ëœ ê³³ì…ë‹ˆë‹¤. ê³ ì¡°ì„ ì˜ ë‹¨êµ° ì‹ í™”, ê³ êµ¬ë ¤ì˜ ì£¼ëª½ ì‹ í™”, ì‹ ë¼ì˜ ë°•í˜ê±°ì„¸ ì‹ í™” ë“± ëŒ€ë¶€ë¶„ì˜ ì‹ í™”ë“¤ì€ ë‚˜ë¼ë¥¼ ì„¸ìš´ ì‹œì¡°ê°€ í•˜ëŠ˜ì—ì„œ ë‚´ë ¤ì˜¤ê±°ë‚˜ ì•Œì—ì„œ íƒœì–´ë‚œ ê²ƒì´ ë§ì•„ìš”. ê·¸ëŸ°ë° ì œì£¼ë„ì˜ ì‹ í™”ëŠ” ë•…ì—ì„œ ì†Ÿì•„ë‚˜ì§€ìš”. ë˜ ì‹œì¡°ê°€ í•œ ëª…ì´ ì•„ë‹ˆë¼ ì„¸ ëª…ì¸ ì ë„ íŠ¹ì´í•´ìš”.
ê·¸ë¦¬ê³  ë²½ë‘êµ­ì˜ ê³µì£¼ë“¤ì´ ê³¡ì‹ê³¼ ê°€ì¶•ì„ ê°€ì ¸ì™”ë‹¤ëŠ” ì´ì•¼ê¸°ëŠ” ë°”ë‹¤ë¥¼ í†µí•´ì„œ ì™¸ë˜ ë¬¸í™”ê°€ ë“¤ì–´ì™”ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤
```

## RAG Chatbot êµ¬í˜„

ìœ„ì˜ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ êµ¬í˜„í•˜ì—¬ ì• ë¶€ë¶„ì€ ê°™ì•„ì„œ ìƒëµí•˜ê² ë‹¤. ë°‘ì˜ ì½”ë“œë¥¼ í†µí•´ ìœ„ì—ì„œ êµ¬í˜„í•œ ragë¥¼ gradioë¥¼ í†µí•´ ì‚¬ìš©í•´ ë³¼ ìˆ˜ ìˆë‹¤.

```python
import gradio as gr

# app start
def response(message, history):
     chat_history = []
     for human,ai in history:
         chat_history.extend(
              [HumanMessage(content=human),
               AIMessage(content=ai)])
     ollama_response=rag_chain.invoke({"input": message, "chat_history": chat_history})
     return ollama_response["answer"]

theme = gr.themes.Soft(font=[gr.themes.GoogleFont("Jua"),"sans-serif"])

# primary_hue=gr.themes.colors.teal, í…Œë§ˆì—ì„œ ì‹œì„ ì„ ë„ëŠ” ìƒ‰ìƒ
# secondary_hue=gr.themes.colors.cyan) ë³´ì¡°ìš”ì†Œ
# nautral_hue í…ìŠ¤íŠ¸ ë° ê¸°íƒ€ ì¤‘ë¦½ ìš”ì†Œ

gr.ChatInterface(
        fn=response,
        textbox=gr.Textbox(placeholder="ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”", container=False, scale=7),
        # ì±„íŒ…ì°½ì˜ í¬ê¸°ë¥¼ ì¡°ì ˆí•œë‹¤.
        chatbot=gr.Chatbot(height=600),
        title="âœ¨ì œì£¼ ì—­ì‚¬ ê°€ì´ë“œ llmâœ¨",
        # description="ì œì£¼ ì—­ì‚¬ ê°€ì´ë“œ ì±—ë´‡ì…ë‹ˆë‹¤.",
        theme=theme,
        examples=[["ì œì£¼ ë‹¤í¬ íˆ¬ì–´ë¦¬ì¦˜ ê´€ê´‘ì§€ í•˜ë‚˜ ì•Œë ¤ì¤˜"],["ê·¸ì— ì–½íŒ ì—­ì‚¬ì  ì‚¬ì‹¤ë„ ì•Œë ¤ì¤˜"], ["ì œì£¼ ì—­ì‚¬ì— ëŒ€í•´ ì•Œë ¤ì¤˜"]],
        retry_btn="ë‹¤ì‹œë³´ë‚´ê¸° â†©",
        undo_btn="ì´ì „ì±— ì‚­ì œ âŒ",
        clear_btn="ì „ì±— ì‚­ì œ ğŸ’«"
).launch()

```

## ì‹¤í–‰ ê²°ê³¼

![rag2](result2_ollamaembedding.png)

## ê³ ì°°

í”„ë¡œì íŠ¸ë¥¼ í†µí•´ ragë¥¼ ê°„ë‹¨íˆ êµ¬í˜„í•´ë³´ë©´ì„œ ragì— ëŒ€í•´ ë°°ì› ë‹¤. ì‹¤ì œë¡œ gradioë¥¼ í†µí•´ ì±—ë´‡ìœ¼ë¡œ ì‚¬ìš©í–ˆì„ ë•Œ ì•„ì‰¬ìš´ ì ì´ ëª‡ê°€ì§€ ìˆì—ˆë‹¤. í•œ ê°€ì§€ëŠ” ë¬¸ì„œ ì„ë² ë”©ì´ë‹¤. chromadbì— ëŒ€í•´ ë¯¸ìˆ™í•´ì„œ ëª‡ë²ˆ ìƒˆë¡­ê²Œ êµ¬ì¶•ì„ ì§„í–‰í–ˆëŠ”ë° ì§„í–‰í•  ë•Œ ë§ˆë‹¤ ì•½ê°„ì”© ë‹¬ë¼ì§€ëŠ” ê²ƒì„ ëŠê¼ˆë‹¤.
ë‹¤ë¥¸ í•œ ê°€ì§€ëŠ” ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ì•„ì§ ì í•©í•œ ê²ƒì„ ì°¾ì§€ ëª»í•œ ì ì´ë‹¤. ì„ì˜ë¡œ ìˆ˜ì •ì„ í•˜ê³  ì§„í–‰í–ˆì„ ë•Œ ì´ìƒí•œ ê²°ê³¼ë¥¼ ì–»ì–´ ì²˜ìŒìœ¼ë¡œ ëŒì•„ê°€ê²Œ ë˜ì—ˆë‹¤. ë§ˆì§€ë§‰ì€ ì‹¤ì œë¡œ ì±—ë´‡ì„ ì‚¬ìš©í•  ë•Œ í•œì •ì ì¸ ì§ˆë¬¸ì— ì˜¬ë°”ë¥´ê²Œ ì‘ë™í•œë‹¤ëŠ” ì ì´ë‹¤. ìœ„ì— ê²°ê³¼ì—ì„œ "ì œì£¼ ë‹¤í¬ íˆ¬ì–´ë¦¬ì¦˜ í•˜ë‚˜ ë§í•´ì¤˜"ë¼ê³  ì‘ì„±í–ˆì„ ë•ŒëŠ” ì˜ ì‘ë™í•˜ëŠ”ë° "ì œì£¼ ë‹¤íŠ¸ íˆ¬ì–´ë¦¬ì¦˜ í•˜ë‚˜ ì¶”ì²œí•´ì¤˜"ë¼ê³  í•˜ë©´ ì´ìƒí•˜ê²Œ ë‹µë³€í•˜ëŠ” ê²½ìš°ê°€ ì¢…ì¢…ìˆì—ˆë‹¤. ì´ í”„ë¡œì íŠ¸ë¥¼ ì‹¬í™”ì‹œí‚¨ë‹¤ë©´ ìœ„ì˜ ì„¸ ê°€ì§€ì— ëŒ€í•´ì„œ ë°œì „ì‹œí‚¤ê³  ì‹¶ë‹¤.

- ë°‘ì˜ ì‚¬ì§„ì€ ì„ë² ë”©ì´ ì˜ëª»ë˜ì„œ ì¼ì–´ë‚œ í—¤í”„ë‹ìœ¼ë¡œ ìƒê°í•´ì„œ ìƒˆë¡­ê²Œ ë²¡í„°ìŠ¤í† ì–´ êµ¬ì¶• í›„ì—ëŠ” ì¢‹ì•„ì¡Œë‹¤. + ì‚¼ì„±í˜ˆì€ ì´ë„ì´ë™ì— ìˆë‹¤.
  ![rag1](result_ollamaembedding.png)

## References

### Markdown

- https://aws.amazon.com/ko/what-is/retrieval-augmented-generation/

- https://velog.io/@jjlee6496/RAG%EB%9E%80

- https://wikidocs.net/233780

### chatbot

- https://velog.io/@t_wave/gradiolangchainchatbot

- https://python.langchain.com/v0.2/docs/tutorials/qa_chat_history/

### chromadb

- https://api.python.langchain.com/en/latest/vectorstores/langchain_chroma.vectorstores.Chroma.html

- https://how.wtf/how-to-use-chroma-db-step-by-step-guide.html

### css-font

- https://fonts.google.com/selection/embed

- https://www.gradio.app/guides/theming-guide
