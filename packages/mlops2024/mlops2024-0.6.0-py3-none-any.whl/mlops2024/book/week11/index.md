# Week 11

**LLaMA Factory를 활용한 대규모 언어 모델 파인튜닝**

LLaMA Factory는 LLMs 파인튜닝 과정을 단순화하고 파인튜닝 중 시각화 기능을 제공하는 강력하고 사용하기 쉬운 도구입니다. 다음과 같은 주제를 다룰 예정입니다:

1. LLM 파인튜닝 소개

- LLM 파인튜닝의 개념과 중요성 설명
- 파인튜닝 과정에 포함된 주요 단계 논의
- 처음부터 학습하는 것과 비교하여 파인튜닝의 장점 강조

LLM 파인튜닝은 이미 사전 학습된 대규모 언어 모델을 특정 작업에 적합하도록 추가로 학습시키는 것을 의미합니다. 파인튜닝은 제한된 데이터와 계산 자원으로도 뛰어난 성능을 얻을 수 있어 처음부터 학습하는 것보다 효율적입니다. 주요 단계로는 적합한 사전학습 모델 선택, 목표 작업 관련 데이터셋 준비, 낮은 학습률로 추가 학습, 검증 데이터셋으로 성능 평가 등이 있습니다.

2. 최신 파인튜닝 전략

- LoRA(Low-Rank Adaptation)와 대규모 언어 모델 파인튜닝에서의 장점 소개
- QLoRA(Quantized LoRA)와 성능을 유지하면서 메모리 사용량을 줄이는 능력 설명
- PEFT(Parameter-Efficient Fine-Tuning)와 사전 학습된 모델을 특정 작업에 적응시키는 데 있어서의 효과성 논의
- 다양한 파인튜닝 전략 비교 및 모범 사례 제시

LoRA는 낮은 계산/메모리 비용으로 수십억 개 매개변수 모델을 특정 작업에 적응시키는 저순위 근사 기법입니다. QLoRA는 사전 학습된 언어 모델을 4비트로 양자화하여 메모리 사용량을 크게 줄이면서 16비트 파인튜닝 성능을 유지합니다. PEFT는 적은 수의 핵심 매개변수만 조정해 계산/저장 비용을 절감하면서 전체 파인튜닝에 버금가는 성능을 제공합니다.

3. LLaMA Factory 소개

- LLaMA Factory 개요 및 기능 제공
- 지원되는 학습 모드(사전 학습, 지도 파인튜닝, 보상 모델링) 설명
- 지원되는 파인튜닝 전략(LoRA 및 QLoRA) 강조
- 비개발자를 위한 WebUI 인터페이스의 장점 토론

LLaMA Factory는 ChatGLM, BaiChuan, Qwen, LLaMA 등 다양한 모델을 지원하고, LoRA, QLoRA와 같은 최신 파인튜닝 방법을 통합하며, WebUI로 편리한 파인튜닝을 제공하는 강력한 LLM 파인튜닝 도구입니다.

4. 설치 및 배포

- LLaMA Factory 설치 과정 안내
- LLaMA Factory 배포를 위한 단계별 지침 제공
- 원하는 LLM(예: ChatGLM, BaiChuan, QWen, LLaMA) 다운로드 및 설정 방법 시연
- 일반적인 문제 해결 및 문제 해결 팁 제공

공식 저장소의 단계에 따라 LLaMA Factory를 설치하고 배포할 수 있습니다. 가상 환경을 만들고 종속성을 설치한 후, 원하는 LLM을 다운로드하세요. git lfs를 사용하거나 Hugging Face에서 직접 다운로드하는 두 가지 방법이 있습니다.

5. 파인튜닝 시작하기

- LLaMA Factory WebUI 인터페이스와 구성 요소 둘러보기
- 기본 모델 학습 구성 매개변수 설명
- 다양한 학습 단계와 목적 논의
- 적절한 하이퍼파라미터(학습률, epochs 등) 선택에 대한 지침 제공
- 파인튜닝 프로세스를 미리 보고 시작하는 방법 시연

LLaMA Factory WebUI는 학습 구성과 학습, 평가, 채팅, 내보내기 탭으로 나뉩니다. 학습 구성에서는 모델 이름, 어댑터 경로, 파인튜닝 방법, 체크포인트 등 기본 설정을, 학습 탭에서는 학습 단계, 데이터셋, 하이퍼파라미터 등을 지정합니다. 매개변수를 설정한 후 미리보기를 통해 명령어를 확인하고 시작 버튼을 클릭하여 파인튜닝을 시작할 수 있습니다.

6. 모델 테스트 및 평가

- LLaMA Factory의 Chat 탭을 사용하여 파인튜닝된 모델을 테스트하는 방법 설명
- 파인튜닝된 체크포인트를 로드하고 모델과 상호 작용하는 방법 시연
- 파인튜닝된 모델의 성능 평가의 중요성 토론
- 모델의 응답을 평가하고 필요한 조정을 수행하기 위한 지침 제공

Chat 탭에서 가장 최근에 파인튜닝된 체크포인트를 로드하여 파인튜닝 데이터셋에서 질문을 입력하고 LLM의 응답을 관찰함으로써 모델을 테스트할 수 있습니다. 모델의 성능을 평가하고 필요한 경우 추가 파인튜닝을 수행하는 것이 중요합니다.

7. 모델 내보내기 및 배포

- 파인튜닝된 모델 내보내기 과정 안내
- 내보내기 구성 옵션(내보내기 디렉토리, 최대 청크 크기) 설명
- 모델 양자화 및 이점 논의
- FastChat 또는 기타 도구를 사용하여 파인튜닝된 모델을 배포하기 위한 지침 제공

Export 탭에서 내보내기 디렉토리와 최대 청크 크기를 지정하고 Start Export 버튼을 클릭하여 파인튜닝된 모델을 내보낼 수 있습니다. 내보내기 과정에서 모델을 4비트나 8비트로 양자화하여 배포 크기를 줄일 수도 있습니다. 내보낸 모델은 FastChat 등의 도구를 사용하여 배포할 수 있습니다.

```{tableofcontents}

```
