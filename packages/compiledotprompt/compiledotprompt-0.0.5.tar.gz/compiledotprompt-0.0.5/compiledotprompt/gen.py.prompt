A python cli application, built using the "click" framework. It takes prompts 
stored in the local filesystem and produces code files, stored along with the prompts.

The prompt files have ".prompt" suffix. For example, a prompt to produce example.py 
will be stored in the example.py.prompt file.

Prompt files may contain @raw(filename) and @prompt(filename) directives. Example:

```
  @raw(path/to/some/file.py)
  Some text @prompt(path/to/another/file.py.prompt) more text.
```
The directives may be inside the text. Use regular expressions to find them.
The application shall replace these directives with the contents of the specified file.
If the file included using @prompt directive itself contains @prompt directives, they should be expanded as well.

To produce code from the prompt use ChatBedrock from langchain_aws package.
Use anthropic.claude-3-5-sonnet-20240620-v1:0 model in us-east-1 region.
Make sure you initialize the model exactly like this:
```
    chat = ChatBedrock(
        model_id="anthropic.claude-3-5-sonnet-20240620-v1:0",
        region_name="us-east-1"
    )
```

Use these system instructions for the AI:
<instructions>Output just the file content, nothing else. Do not print any 
introductory text before the code. Do not enclose the code in triple quotes. 
Include a comment in the code
saying that this file was produced by AI from a prompt and shouldn't 
be edited directly, unless generating json or other file formats
that don't support comments.</instructions>

Also provide a one-shot example, such as 
<user>Hello world in python</user>
<assistant>print('Hello world')</assistant>

Please avoid these errors and warnings:
ValueError: System message must be at beginning of message list.
LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.
