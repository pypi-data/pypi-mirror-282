{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using GNN layers\n",
    "\n",
    "The current library implements multiple state-of-the-art graph neural networks. In this tutorial, you will learn how to use the **GCN**, **GIN**, **GINE**, **GPS**, **Gated-GCN** and **PNA** layers in a simple `forward` context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch_geometric as pyg\n",
    "from torch_geometric.data import Data, Batch\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from graphium.nn.pyg_layers import (\n",
    "    GCNConvPyg,\n",
    "    GINConvPyg,\n",
    "    GatedGCNPyg,\n",
    "    GINEConvPyg,\n",
    "    GPSLayerPyg,\n",
    "    PNAMessagePassingPyg\n",
    ")\n",
    "\n",
    "_ = torch.manual_seed(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first create some simple batched graphs that will be used accross the examples. Here, `bg` is a batch containing 2 graphs with random node features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(edge_index=[2, 7], feat=[7, 5], edge_feat=[7, 13], batch=[7], ptr=[3])\n"
     ]
    }
   ],
   "source": [
    "in_dim = 5          # Input node-feature dimensions\n",
    "in_dim_edges = 13   # Input edge-feature dimensions\n",
    "out_dim = 11        # Desired output node-feature dimensions\n",
    "out_dim_edges = 15  # Desired output edge-feature dimensions\n",
    "\n",
    "\n",
    "# Let's create 2 simple pyg graphs. \n",
    "# start by specifying the edges with edge index\n",
    "edge_idx1 = torch.tensor([[0, 1, 2],\n",
    "                          [1, 2, 3]])\n",
    "edge_idx2 = torch.tensor([[2, 0, 0, 1],\n",
    "                          [0, 1, 2, 0]])\n",
    "\n",
    "# specify the node features, convention with variable x\n",
    "x1 = torch.randn(edge_idx1.max() + 1, in_dim, dtype=torch.float32)\n",
    "x2 = torch.randn(edge_idx2.max() + 1, in_dim, dtype=torch.float32)\n",
    "\n",
    "# specify the edge features in e\n",
    "e1 = torch.randn(edge_idx1.shape[-1], in_dim_edges, dtype=torch.float32)\n",
    "e2 = torch.randn(edge_idx2.shape[-1], in_dim_edges, dtype=torch.float32)\n",
    "\n",
    "# make the pyg graph objects with our constructed features\n",
    "g1 = Data(feat=x1, edge_index=edge_idx1, edge_feat=e1)\n",
    "g2 = Data(feat=x2, edge_index=edge_idx2, edge_feat=e2)\n",
    "\n",
    "# put the two graphs into a Batch graph\n",
    "bg = Batch.from_data_list([g1, g2])\n",
    "\n",
    "# The batched graph will show as a single graph with 7 nodes\n",
    "print(bg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCN Layer\n",
    "\n",
    "To use the GCN layer from the *Kipf et al.* paper, the steps are very simple. We create the layer with the desired attributes, and apply it to the graph.\n",
    "\n",
    "<sub>Kipf, Thomas N., and Max Welling. \"Semi-supervised classification with graph convolutional networks.\" arXiv preprint arXiv:1609.02907 (2016).</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 5])\n",
      "GCNConvPyg(5 -> 11, activation=relu)\n",
      "torch.Size([7, 11])\n"
     ]
    }
   ],
   "source": [
    "# The GCN method doesn't support edge features, so we ignore them\n",
    "graph = deepcopy(bg)\n",
    "print(graph.feat.shape)\n",
    "\n",
    "# We create the layer\n",
    "layer = GCNConvPyg(\n",
    "            in_dim=in_dim, out_dim=out_dim, \n",
    "            activation=\"relu\", dropout=.3, normalization=\"batch_norm\")\n",
    "\n",
    "# We apply the forward loop on the node features\n",
    "graph = layer(graph)\n",
    "\n",
    "# 7 is the number of nodes, 5 number of input features and 11 number of output features\n",
    "print(layer)\n",
    "print(graph.feat.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GIN Layer\n",
    "\n",
    "To use the GIN layer from the *Xu et al.* paper, the steps are identical to GCN.\n",
    "\n",
    "<sub>Xu, Keyulu, et al. \"How powerful are graph neural networks?.\" arXiv preprint arXiv:1810.00826 (2018).</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 5])\n",
      "GINConvPyg(5 -> 11, activation=relu)\n",
      "torch.Size([7, 11])\n"
     ]
    }
   ],
   "source": [
    "graph = deepcopy(bg)\n",
    "print(graph.feat.shape)\n",
    "\n",
    "# We create the layer\n",
    "layer = GINConvPyg(\n",
    "            in_dim=in_dim, out_dim=out_dim, \n",
    "            activation=\"relu\", dropout=.3, normalization=\"batch_norm\")\n",
    "\n",
    "# We apply the forward loop on the node features\n",
    "graph = layer(graph)\n",
    "\n",
    "# 7 is the number of nodes, 5 number of input features and 11 number of output features\n",
    "print(layer)\n",
    "print(graph.feat.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GINE Layer\n",
    "\n",
    "To use the GINE layer from the *Hu et al.* paper, we also need to provide additional edge features as inputs.\n",
    "\n",
    "<sub>Hu, Weihua, et al. \"Strategies for Pre-training Graph Neural Networks.\" arXiv preprint arXiv:1905.12265 (2019).</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 5])\n",
      "torch.Size([7, 13])\n",
      "GINEConvPyg(5 -> 11, activation=relu)\n",
      "torch.Size([7, 11])\n"
     ]
    }
   ],
   "source": [
    "# The GINE method uses edge features, so we have to pass the input dimension\n",
    "graph = deepcopy(bg)\n",
    "print(graph.feat.shape)\n",
    "print(graph.edge_feat.shape)\n",
    "\n",
    "# We create the layer\n",
    "layer = GINEConvPyg(\n",
    "            in_dim=in_dim, out_dim=out_dim,\n",
    "            in_dim_edges=in_dim_edges,\n",
    "            activation=\"relu\", dropout=.3, normalization=\"batch_norm\")\n",
    "\n",
    "# We apply the forward loop on the node features\n",
    "graph = layer(graph)\n",
    "\n",
    "# 7 is the number of nodes, 5 number of input features and 11 number of output features\n",
    "# 7 is the number of edges, 13 number of input edge features\n",
    "print(layer)\n",
    "print(graph.feat.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPS Layer\n",
    "\n",
    "To use the GPS layer from the *Ramp치코ek et al.* paper, we also need to provide additional edge features as inputs. It is a hybrid approach using both a GNN and transformer in conjunction. Therefore, we further need to specify the GNN type and attention type used in the layer.\n",
    "\n",
    "<sub>Ramp치코ek, Ladislav, et al. \"Recipe for a General, Powerful, Scalable Graph Transformer.\" arXiv preprint arXiv:2205.12454 (2022).</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 5])\n",
      "torch.Size([7, 13])\n",
      "GPSLayerPyg(5 -> 11, activation=relu)\n",
      "torch.Size([7, 11])\n",
      "torch.Size([7, 13])\n"
     ]
    }
   ],
   "source": [
    "graph = deepcopy(bg)\n",
    "print(graph.feat.shape)\n",
    "print(graph.edge_feat.shape)\n",
    "\n",
    "# We create the layer\n",
    "layer = GPSLayerPyg(\n",
    "            in_dim=in_dim, out_dim=out_dim,\n",
    "            in_dim_edges=in_dim_edges,\n",
    "            mpnn_type = \"pyg:gine\", attn_type = \"full-attention\",\n",
    "            activation=\"relu\", dropout=.3, normalization=\"batch_norm\")\n",
    "\n",
    "# We apply the forward loop on the node features\n",
    "graph = layer(graph)\n",
    "\n",
    "# 7 is the number of nodes, 5 number of input features and 11 number of output features\n",
    "# 7 is the number of edges, 13 number of input edge features\n",
    "print(layer)\n",
    "print(graph.feat.shape)\n",
    "print(graph.edge_feat.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gated-GCN Layer\n",
    "\n",
    "To use the Gated-GCN layer from the *Bresson et al.* paper, the steps are different since the layer not only requires edge features as inputs, but also outputs new edge features. Therefore, we have to further specify the number of output edge features\n",
    "\n",
    "<sub>Bresson, Xavier, and Thomas Laurent. \"Residual gated graph convnets.\" arXiv preprint arXiv:1711.07553 (2017).</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 5])\n",
      "torch.Size([7, 13])\n",
      "GatedGCNPyg()\n",
      "torch.Size([7, 11])\n",
      "torch.Size([7, 15])\n"
     ]
    }
   ],
   "source": [
    "graph = deepcopy(bg)\n",
    "print(graph.feat.shape)\n",
    "print(graph.edge_feat.shape)\n",
    "\n",
    "# We create the layer\n",
    "layer = GatedGCNPyg(\n",
    "            in_dim=in_dim, out_dim=out_dim,\n",
    "            in_dim_edges=in_dim_edges, out_dim_edges=out_dim_edges,\n",
    "            activation=\"relu\", dropout=.3, normalization=\"batch_norm\")\n",
    "\n",
    "# We apply the forward loop on the node features\n",
    "graph = layer(graph)\n",
    "\n",
    "# 7 is the number of nodes, 5 number of input features and 11 number of output features\n",
    "# 7 is the number of edges, 13 number of input edge features and 15 the the number of output edge features\n",
    "print(layer)\n",
    "print(graph.feat.shape)\n",
    "print(graph.edge_feat.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PNA\n",
    "\n",
    "PNA is a multi-aggregator method proposed by *Corso et al.*. It supports 2 types of aggregations, convolutional *PNA-conv* or message passing *PNA-msgpass*. Here, we provide the typically more powerful *PNA-msgpass*. It supports edges as inputs, but doesn't output edges. Here, we need to further specify the aggregators and scalers specific to this layer.\n",
    "\n",
    "<sub>Corso, Gabriele, et al. \"Principal Neighbourhood Aggregation for Graph Nets.\"\n",
    "arXiv preprint arXiv:2004.05718 (2020).</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 5])\n",
      "torch.Size([7, 13])\n",
      "PNAMessagePassingPyg()\n",
      "torch.Size([7, 11])\n"
     ]
    }
   ],
   "source": [
    "graph = deepcopy(bg)\n",
    "print(graph.feat.shape)\n",
    "print(graph.edge_feat.shape)\n",
    "\n",
    "# We create the layer, and need to specify the aggregators and scalers\n",
    "layer = PNAMessagePassingPyg(\n",
    "    in_dim=in_dim, out_dim=out_dim,\n",
    "    in_dim_edges=in_dim_edges,\n",
    "    aggregators=[\"mean\", \"max\", \"min\", \"std\"],\n",
    "    scalers=[\"identity\", \"amplification\", \"attenuation\"],\n",
    "    activation=\"relu\", dropout=.3, normalization=\"batch_norm\")\n",
    "\n",
    "graph = layer(graph)\n",
    "\n",
    "print(layer)\n",
    "print(graph.feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f4a99d018a205fcbcc0480c84566beaebcb91b08d0414b39a842df533e2a1d25"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('goli': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
