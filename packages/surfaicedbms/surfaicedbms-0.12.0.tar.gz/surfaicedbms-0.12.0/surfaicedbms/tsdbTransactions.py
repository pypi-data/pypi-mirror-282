import psycopg2
import time
import os
from datetime import datetime
import gzip
import yaml
import sys
import csv
import pandas as pd


def load_config(config_file):
    """
    This function helps loading configuration file for accessing database connection related data
    Input: 		Directory of config.yaml file

    Output:		Case 1:	Readen configuration file
                Case 2: None
    """
    with open(config_file, 'r') as stream:
        try:
            config = yaml.safe_load(stream)
            return config
        except yaml.YAMLError as exc:
            print("Error loading the configuration:", exc)
            return None

env_name_config = 'surfaice_dbms_config'
env_name_root = 'surfaice_dbms_root'
config_path = os.getenv(env_name_config)
config = load_config(config_path)
root_path =  os.getenv(env_name_root)

def connectTSDB():
    """
    connectTsdb function is used for connecting PostgreSQL and TimescaleDB database
    Input: 		None
    Output: 	Case 1: conn								... a connection instance for database related operations
    			Case 2: None
    """
    conn = None
    try:
        print("Connectingâ€¦")
        conn = psycopg2.connect(dbname=config['databases']['tsdbDB'],
                                user=config['databases']['tsdbUser'],
                                password=config['databases']['tsdbPassword'],
                                host=config['databases']['tsdbHost'],
                                port=config['databases']['tsdbPort'])
    except(Exception, psycopg2.DatabaseError) as error:
        print(error)
        sys.exit(1)
    print("All good, Connection succesful!")
    return conn



class TsdbTransactions:

#################################################################################################################################################### BULD FUNCTIONS

    def createIdMetaDataTable(self):
        """
        This function creates a table named id_metadata in available PostgreSQL connection for storing tabular metadata regarding generated ids in different phases of product life cycle
        as planning phase, manufacturing phase and quality control phase. Id column of this table has been selected as primary key and serves as validator for ids in other related tables.
        Input:	- None

        Output:	- new table named id_metadata in available connection in case no error occurs
        """
        conn = connectTSDB()
        curr = conn.cursor()
        try:
            curr.execute("CREATE TABLE IF NOT EXISTS \
                        id_metadata (id_type TEXT, id TEXT PRIMARY KEY, registration_time TIMESTAMP NOT NULL, recorder TEXT)")
            conn.commit()
            time.sleep(2)
            curr.close()
            print("id_metadata table has been created")
        except(Exception, psycopg2.DatabaseError) as error:
            conn.rollback()
            print(error)
        finally:
            conn.close()

    def createItemsTable(self):
        """
        This function creates a table named items in available PostgreSQL connection for storing tabular data regarding physical items used/produced in different phases of manufacturing.
        Over items table physical items could be registered and queried.
        Input:	- None

        Output:	- new table named items in available connection in case no error occurs
        """
        conn = connectTSDB()
        curr = conn.cursor()
        try:
            curr.execute("CREATE TABLE IF NOT EXISTS \
                        items (id TEXT PRIMARY KEY, item_type TEXT, registration_time TIMESTAMP NOT NULL, recorder TEXT)")
            conn.commit()
            time.sleep(2)
            curr.close()
            print("items table has been created")
        except(Exception, psycopg2.DatabaseError) as error:
            conn.rollback()
            print(error)
        finally:
            conn.close()

    def createNcTable(self):
        """
        This function creates a hypertable named nc_process in available TimescaleDB connection for storing tabular data, which are generated by formRawData() method.
        To provide a transaction safety workpiece_id column has been referenced to id column of id_metadata table.
        Input:	- None

        Output:	- new hypertable named nc in available connection
        """
        conn = connectTSDB()
        curr = conn.cursor()
        try:
            curr.execute("CREATE TABLE IF NOT EXISTS \
                        nc_process(workpiece_id TEXT REFERENCES id_metadata(id), timestamp TIMESTAMP NOT NULL, featureMeas INTEGER, featureTotal INTEGER, xAbs INTEGER,yAbs INTEGER,\
                        zAbs INTEGER,cAbs INTEGER,aAbs INTEGER, xServo INTEGER,yServo INTEGER,zServo INTEGER,cServo INTEGER,\
                        aServo INTEGER, spindleLoad INTEGER,feedrate INTEGER,spindlespeed INTEGER)")
            curr.execute("SELECT create_hypertable('nc_process','timestamp')")
            conn.commit()
            time.sleep(2)
            curr.close()
            print(f"Hypertable: nc_process has been created")
        except(Exception, psycopg2.DatabaseError) as error:
            conn.rollback()
            print(error)
        finally:
            conn.close()

    def createAccTable(self):
        """
        This function creates a hypertable named acc_process in available TimescaleDB connection for storing tabular data, which are generated by formRawData() method.
        To provide a transaction safety workpiece_id column has been referenced to id column of id_metadata table as a foreign key.
        Input:	- None

        Output:	- new hypertable named acc in available connection
        """
        conn = connectTSDB()
        curr = conn.cursor()
        try:
            curr.execute("CREATE TABLE IF NOT EXISTS \
                        acc_process(workpiece_id TEXT REFERENCES id_metadata(id), counter INTEGER, timestamp TIMESTAMP NOT NULL, xacc DOUBLE PRECISION)")
            curr.execute("SELECT create_hypertable('acc_process','timestamp')")
            conn.commit()
            time.sleep(2)
            curr.close()
            print(f"Hypertable: acc_process has been created")
        except(Exception, psycopg2.DatabaseError) as error:
            conn.rollback()
            print(error)
        finally:
            conn.close()

    def createLiveDataTable(self):
        """
        This function creates a hypertable named livedata_process in available TimescaleDB connection for storing tabular manufacturing process related data.
        The table includes columns for both acc and nc tables is fed with data both tables through data pipe functions pipe_acc and pipe_nc in available database connections.
        To provide a transaction safety workpiece_id column has been referenced to id column of id_metadata table as a foreign key.
        Input:	- None

        Output:	- new hypertable named acc in available connection
        """
        conn = connectTSDB()
        curr = conn.cursor()
        createLiveDataTable = """
            CREATE TABLE livedata_process (
                workpiece_id TEXT REFERENCES id_metadata(id),
                timestamp TIMESTAMP NOT NULL,
                counter INT,
                xacc FLOAT8,
                featuremeas INT,
                featuretotal INT,
                xabs INT,
                yabs INT,
                zabs INT,
                cabs INT,
                aabs INT,
                xServo INT,
                yServo INT,
                zServo INT,
                cServo INT,
                aServo INT,
                spindleload INT,
                feedrate INT,
                spindlespeed INT    
            );
        """
        try:
            curr.execute(createLiveDataTable)
            curr.execute("SELECT create_hypertable('livedata_process','timestamp')")
            conn.commit()
            time.sleep(2)
            curr.close()
            print(f"Hypertable: livedata_process has been created")
        except(Exception, psycopg2.DatabaseError) as error:
            conn.rollback()
            print(error)
        finally:
            conn.close()


    def joinTables(self):
        """
        This function is used for creating pipe functions and triggers in PostgreSQL database to merge content of acc_process and nc_process tables in livedata_process table.
        Pipe functions are responsible for directing every new entry in acc_process and nc_process tables in livedata_process table.
        For activating pipe functions, database triggers have been set in acc_process and nc_process tables to direct newly added dataset.
        Input:	- None

        Output:	- new functions pipe_acc, pipe_nc in PostgreSQL Connection if no error occurs
                - new database triggers acctrigger, nctrigger if no error occurs
        """
        conn = None
        createPipeFunction_acc = """
        -- Trigger function
        CREATE OR REPLACE FUNCTION pipe_acc()
        RETURNS TRIGGER AS $$
        BEGIN
            INSERT INTO livedata_process (workpiece_id, timestamp, counter, xacc)
            VALUES (NEW.workpiece_id, NEW.timestamp, NEW.counter, NEW.xacc);
            RETURN NEW;
        END;
        $$ LANGUAGE plpgsql;
        """
        createAccTrigger = """
        -- Trigger definition on Acc
        CREATE TRIGGER acctrigger
        AFTER INSERT ON acc_process
        FOR EACH ROW
        EXECUTE FUNCTION pipe_acc();
        """
        createPipeFunction_nc =  """
        -- Trigger function
        CREATE OR REPLACE FUNCTION pipe_nc()
        RETURNS TRIGGER AS $$
        BEGIN
            INSERT INTO livedata_process (workpiece_id, timestamp, featuremeas, featuretotal, xabs, yabs, zabs, cabs, aabs, 
            xServo, yServo, zServo, cServo, aServo, spindleload, feedrate, spindlespeed)
            VALUES (NEW.workpiece_id, NEW.timestamp, NEW.featuremeas, NEW.featuretotal, NEW.xabs, NEW.yabs, NEW.zabs, NEW.cabs, 
            NEW.aabs, NEW.xServo, NEW.yServo, NEW.zServo, NEW.cServo, NEW.aServo, NEW.spindleload, NEW.feedrate, NEW.spindlespeed);
            RETURN NEW;
        END;
        $$ LANGUAGE plpgsql;
        """

        createNcTrigger = """
        -- Trigger definition on Nc
        CREATE TRIGGER nctrigger
        AFTER INSERT ON nc_process
        FOR EACH ROW
        EXECUTE FUNCTION pipe_nc();
        """
        try:
            conn = connectTSDB()
            curr = conn.cursor()
            curr.execute(createPipeFunction_acc)
            curr.execute(createPipeFunction_nc)
            conn.commit()
            print("Tigger functions have been created")
        except(Exception, psycopg2.DatabaseError) as error:
            conn.rollback()
            print(error)
        finally:
            conn.close()

        try:
            conn = connectTSDB()
            curr = conn.cursor()
            curr.execute(createAccTrigger)
            curr.execute(createNcTrigger)
            conn.commit()
            time.sleep(2)
            curr.close()
            print("Tiggers for table merging have been activated")
        except(Exception, psycopg2.DatabaseError) as error:
            conn.rollback()
            print(error)
        finally:
            conn.close()

    def registerItemsTrigger(self):
        """
        This function is used for creating pipe function pipe_items and trigger it_metadata_trigger in PostgreSQL database
        on id_metadata table to adress a new workpiece, which has been manufactured.
        pipe_items function checks the last element of id_metadata table, and if it is a process_id a new insert into request to items table will be sended to register a new workpiece
        For activating pipe_items function, database trigger it_metadata_trigger have been set in id_metadata table.
        Input:	- None

        Output:	- new function pipe_items in PostgreSQL connection, if no error occurs
                - new database trigger it_metadata_trigger, if no error occurs
        """
        conn = connectTSDB()
        curr = conn.cursor()
        createPipeFunctionItems = """
        CREATE OR REPLACE FUNCTION pipe_items()
        RETURNS TRIGGER AS $$
        BEGIN
            IF (SELECT id_type FROM id_metadata ORDER BY registration_time DESC LIMIT 1) = 'process_id' THEN
                INSERT INTO items (id, item_type, registration_time, recorder) VALUES (NEW.id, 'workpiece', NEW.registration_time, NEW.recorder);
            END IF;
        
            RETURN NEW;
        END;
        $$ LANGUAGE plpgsql;
        
        """

        createIdMetadataTrigger = """
        CREATE TRIGGER it_metadata_trigger
        AFTER INSERT ON id_metadata
        FOR EACH ROW
        EXECUTE FUNCTION pipe_items();
        """
        try:
            curr.execute(createPipeFunctionItems)
            curr.execute(createIdMetadataTrigger)
            conn.commit()
            time.sleep(2)
            curr.close()
            print("Tiggers for table id_metadata to transfer data in items table has been activated")
        except(Exception, psycopg2.DatabaseError) as error:
            conn.rollback()
            print(error)
        finally:
            conn.close()


    def continousAggregate(self):
        """
        This function creates a materialized view named contlive_process using continous aggregate functionality in available TimescaleDB connection.
        Continous aggregates provide query efficiency due to the precomputed values. The materialized view is fed by data from livedata_process automatically,
        if further data is ingested to livedata_process hypertable.
        In contlive_proces timestamp columns of livedata_process hypertable are organized as time intervals in 10 seconds microseconds resolution,
        for keeping the consistency of data, other columns with valuable information are aggregated with average or max functions.
        This continous aggregate function is executed in an autocommit isolation level to commit immediately and disable any transactional behaviour.
        Input:	- None

        Output:	- new materialized view named contlive_process in available connection
        """
        conn = connectTSDB()
        curr = conn.cursor()
        from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT
        conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)
        continousAggregateLive = """
        CREATE MATERIALIZED VIEW contLive_process
        WITH (timescaledb.continuous) AS
        SELECT  workpiece_id,
           time_bucket(INTERVAL '10 microsecond', timestamp) AS bucket,
           MAX(counter) AS COUNTER_MAX,
           AVG(xacc) AS XACC_AVG,
           AVG(xabs) AS XABS_AVG,
           AVG(yabs) AS YABS_AVG,
           AVG(zabs) AS ZABS_AVG,
           AVG(cabs) AS CABS_AVG,
           AVG(aabs) AS AABS_AVG,
           AVG(spindleload) AS SPINDLELOAD_AVG,
           AVG(feedrate) AS FEEDRATE_AVG,
           AVG(spindlespeed) AS SPINDLESPEED_AVG
        FROM livedata_process
        GROUP BY workpiece_id, bucket
        ORDER BY workpiece_id, bucket;

        """
        continous = """                                                                             ## will be checked again
        SELECT add_continuous_aggregate_policy('contlive_process');
        """
        try:
            curr.execute(continousAggregateLive)
            #curr.execute(continous)
            conn.commit()
            time.sleep(2)
            curr.close()
            print("continous aggregate with auto refresh policy has been created")
        except(Exception, psycopg2.DatabaseError) as error:
            conn.rollback()
            print(error)
        finally:
            conn.close()


    def createManufacturingOperationsTable(self):
        """
        This function creates a table named manufacturing_operations in available PostgreSQL connection for storing tabular data, which are generated by formMetaData() method.
        To provide a transaction safety process_id column has been referenced to id column of id_metadata table as a foreign key.
        Input:	- None

        Output:	- new table named manufacturing_operations in available connection
        """
        conn = connectTSDB()
        curr = conn.cursor()
        try:
            curr.execute("CREATE TABLE IF NOT EXISTS \
                        manufacturing_operations(process_id TEXT REFERENCES id_metadata(id), manopt_id TEXT, ts_operation_start TIMESTAMP NOT NULL, ts_operation_end TIMESTAMP NOT NULL, \
                        ts_position_start TIMESTAMP NOT NULL, ts_position_end TIMESTAMP NOT NULL, ts_acc_start TIMESTAMP NOT NULL, ts_acc_end TIMESTAMP NOT NULL)")
            conn.commit()
            time.sleep(2)
            curr.close()
            print(f"Table: manufacturing_operations has been created")
        except(Exception, psycopg2.DatabaseError) as error:
            conn.rollback()
            print(error)
        finally:
            conn.close()


    def createRarzTable(self):
        """

        """
        conn = connectTSDB()
        curr = conn.cursor()
        try:
            curr.execute("CREATE TABLE IF NOT EXISTS \
                        rarz(inspection_id TEXT REFERENCES id_metadata(id), experiment_id TEXT,\
                            window_id INTEGER, rz DOUBLE PRECISION, ra DOUBLE PRECISION)")
            conn.commit()
            time.sleep(2)
            curr.close()
            print(f"Table: rarz has been created")
        except(Exception, psycopg2.DatabaseError) as error:
            conn.rollback()
            print(error)
        finally:
            conn.close()



#################################################################################################################################################### INGESTION FUNCTIONS

    def ingestNc(self):
        """
        This function is used for storing tabular data, which is collected by cnc machine in available TimescaleDB connection.
        Input:	- nc_output.csv.gz in data\outputs\processed_manufacturing_data directory   ... tabular data of manufacturing process, which are gained from formRawData() method.

        Output:	- ingestion of tabular manufacturing process data in nc table in case no error occurs
        """
        conn = connectTSDB()
        curr = conn.cursor()
        relative_path = os.path.join(root_path, 'data\outputs\processed_manufacturing_data')
        copy_sql = f"COPY nc_process FROM stdin WITH CSV HEADER"
        try:
            with gzip.open(relative_path+"\\nc_output.csv.gz", 'rt') as f:
                curr.copy_expert(sql=copy_sql, file=f)
            conn.commit()
            time.sleep(2)
            curr.close()
            print(f"Data has been ingested to nc_process")
        except(Exception, psycopg2.DatabaseError) as error:
            conn.rollback()
            print(error)
        finally:
            conn.close()

    def ingestAcc(self):
        """
        This function is used for storing tabular data, which is collected by acceleration sensor in available TimescaleDB connection.
        Input:	- acc_output.csv.gz in data\outputs\processed_manufacturing_data directory   ... tabular data of manufacturing process, which are gained from formRawData() method.

        Output:	- ingestion of tabular manufacturing process data in acc table in case no error occurs
        """
        conn = connectTSDB()
        curr = conn.cursor()
        relative_path = os.path.join(root_path, 'data\outputs\processed_manufacturing_data')
        copy_sql = f"COPY acc_process FROM stdin WITH CSV HEADER"
        try:
            with gzip.open(relative_path+"\\acc_output.csv.gz", 'rt') as f:
                curr.copy_expert(sql=copy_sql, file=f)
            conn.commit()
            time.sleep(2)
            curr.close()
            print(f"Data has been ingested to acc_process")
        except(Exception, psycopg2.DatabaseError) as error:
            conn.rollback()
            print(error)
        finally:
            conn.close()


    def ingestManufacturingOperations(self):
        """
        This function is used for storing metadata about manufacturing process generated by edge application in available PostgreSQL connection.
        Input:	- manopt_output.csv.gz in data\outputs\manufacturing_operations_metadata directory  ... tabular metadata of manufacturing operations, which are gained from formMetaData() method.

        Output:	- ingestion of tabular metadata in rarz table in case no error occurs
        """
        conn = connectTSDB()
        curr = conn.cursor()
        relative_path = os.path.join(root_path, 'data\outputs\manufacturing_operations_metadata')
        copy_sql = f"COPY manufacturing_operations FROM stdin WITH CSV HEADER"
        try:
            with gzip.open(relative_path+"\\manopt_output.csv.gz", 'rt') as f:
                curr.copy_expert(sql=copy_sql, file=f)
            conn.commit()
            time.sleep(2)
            curr.close()
            print(f"Data has been ingested to manufacturing")
        except(Exception, psycopg2.DatabaseError) as error:
            conn.rollback()
            print(error)
        finally:
            conn.close()


    def ingestRarz(self):
        """
        This function is used for storing results of Ra Rz calculation in available PostgreSQL connection.
        Input:		- rarz_output.csv.gz in data\outputs\rarz directory                    ... tabular data of ra rz calculations, which are gained from node_calc_RaRz_static_window_size() method

        Output:		- ingestion of tabular data in rarz table in case no error occurs
        """
        conn = connectTSDB()
        curr = conn.cursor()
        relative_path = os.path.join(root_path, 'data\outputs\\rarz')
        copy_sql = f"COPY rarz FROM stdin WITH CSV HEADER"
        try:
            with gzip.open(relative_path+"\\rarz_output.csv.gz", 'rt') as f:
                curr.copy_expert(sql=copy_sql, file=f)
            conn.commit()
            time.sleep(2)
            curr.close()
            print(f"Data has been ingested to rarz")
        except(Exception, psycopg2.DatabaseError) as error:
            conn.rollback()
            print(error)
        finally:
            conn.close()

#################################################################################################################################################### SINGLE WRITE FUNCTIONS

    def registerProcess(self, processId):
        """
        Gives an INSERT INTO request to id_metadata table for registering new process id.
        Input:		- inspection_id                                                                   ... identification number of manufacturing process

        Output:		- new entry in id_metadata table about new process id in case no error occurs
        """
        conn = connectTSDB()
        curr = conn.cursor()
        recorder = "ift"
        id_type = "process_id"
        current_time = datetime.fromtimestamp(time.time())
        insert_query = f"INSERT INTO id_metadata (id_type, id, registration_time, recorder) VALUES (%s, %s, %s, %s)"
        data = (id_type, processId, str(current_time), recorder)
        try:
            curr.execute(insert_query, data)
            conn.commit()
            time.sleep(2)
            curr.close()
            print("process_id has been registered to id_metadata")
        except(Exception, psycopg2.DatabaseError) as error:
            conn.rollback()
            print(error)
        finally:
            conn.close()

    def registerInspection(self, inspection_id):
        """
        Gives an INSERT INTO request to id_metadata table for registering new inspection id.
        Input:		- inspection_id                                                                   ... identification number of quality measurment

        Output:		- new entry in id_metadata table about new inspection id in case no error occurs
        """
        conn = connectTSDB()
        curr = conn.cursor()
        recorder = "ift"
        id_type = "inspection_id"
        current_time = datetime.fromtimestamp(time.time())
        insert_query = f"INSERT INTO id_metadata (id_type, id, registration_time, recorder) VALUES (%s, %s, %s, %s)"
        data = (id_type, inspection_id, str(current_time), recorder)
        try:
            curr.execute(insert_query, data)
            conn.commit()
            time.sleep(2)
            curr.close()
            print("inspection_id has been registered to id_metadata")
        except(Exception, psycopg2.DatabaseError) as error:
            conn.rollback()
            print(error)
        finally:
            conn.close()


    def registerMachine(self, machineData, current_time, creator, logger):
        """
        Gives an INSERT INTO request to items table for registering new machine of cam setup
        Input:		- machineData                               ... data from machine instance to extract its id for registering
                    - current_time                              ... current time as string                      ### can be optimized further
        			- creator								    ... registering user name
        			- logger                                    ... logger instance for archiving

        Output:		new entry in items table about new machine in case no error occurs
        """
        conn = connectTSDB()
        curr = conn.cursor()
        try:
            insert_query = f"INSERT INTO items (ID, item_type, registration_time, recorder) VALUES (%s, %s, %s, %s)"
            data = (machineData["_id"], "Machine", current_time, creator)
            curr.execute(insert_query, data)
            conn.commit()
            time.sleep(2)
            curr.close()
            logger.info('Machine has been registered in items')
        except(Exception, psycopg2.DatabaseError) as error:
            conn.rollback()
            print(error)
        finally:
            conn.close()
    
    def registerTool(self, toolId, current_time, creator, logger):
        """
        Gives an INSERT INTO request to items table for registering new tools of cam setup
        Input:		- toolId                                    ... id string of tool instance
                    - current_time                              ... current time as string                      ### can be optimized further
        			- creator								    ... registering user name
        			- logger                                    ... logger instance for archiving

        Output:		new entry in items table about new tool in case no error occurs
        """
        conn = connectTSDB()
        curr = conn.cursor()
        try:
            insert_query = f"INSERT INTO items (ID, item_type, registration_time, recorder) VALUES (%s, %s, %s, %s)"
            data = (toolId, "Tool", current_time, creator)
            curr.execute(insert_query, data)
            conn.commit()
            time.sleep(2)
            curr.close()
        except(Exception, psycopg2.DatabaseError) as error:
            conn.rollback()
            print(error)
        finally:
            conn.close()

    def registerIdMetaData(self, workpiece_ID, editor, logger):
        """
        Gives an INSERT INTO request to id_metadata table for registering newly generated workpiece instance
        Input:		- workpiece_ID                              ... id string of newly generated workpiece instance
        			- editor								    ... registering user name
        			- logger                                    ... logger instance for archiving

        Output:		new entry in id_metadata table about new workpiece in case no error occurs
        """
        conn = connectTSDB()
        curr = conn.cursor()
        try:
            insert_query = f"INSERT INTO id_metadata (id_type, id, registration_time, recorder) VALUES (%s, %s, %s, %s)"
            current_timestamp = time.time()
            current_timestamp= datetime.utcfromtimestamp(current_timestamp).strftime('%Y-%m-%d %H:%M:%S')
            recorder=editor
            data = ("workpiece_id", workpiece_ID, str(current_timestamp), recorder)
            curr.execute(insert_query, data)
            conn.commit()
            time.sleep(2)
            curr.close()
            logger.info('id metadata has been registered')
        except(Exception, psycopg2.DatabaseError) as error:
            conn.rollback()
            print(error)
        finally:
            conn.close()


#################################################################################################################################################### QUERIES???
    def showItems(self):
        """
        This function displays query results about all registered items in items table on console
        Input:		- None

        Output:		- query results in case no error occurs
        """
        conn = connectTSDB()
        curr = conn.cursor()
        queryItems = f"SELECT * FROM items;"
        try:
            curr.execute(queryItems)
            results = curr.fetchall()
            print("---------------------------")
            print(f"REGISTERED ITEMS:")
            print("---------------------------")
            for row in results:
                print("item id: ", row[0])
                print("item type: ", row[1])
                print("registration time: ", row[2])
                print("recorder: ", row[3])
                print("---------------------------")
        except(Exception, psycopg2.DatabaseError) as error:
            conn.rollback()
            print(error)
        finally:
            conn.close()


    def findItemWorkpieceSince(self, datetime):
        """
        This function displays query results and returns a list of registered process ids in items table beginning from a certain datetime
        Input:		- datetime                                          ... desired beginning time for query

        Output:		- idList of registered ids in items table beginning from given datetime in case no error occurs
        """
        conn = connectTSDB()
        curr = conn.cursor()
        queryItems = f"SELECT id FROM items WHERE registration_time >= %s AND item_type = 'workpiece';"
        try:
            curr.execute(queryItems, (datetime,))
            results = list(curr.fetchall())
            idList = []
            for i in range(len(results)):
                idList.append(str(results[i][0]))
            return idList
        except(Exception, psycopg2.DatabaseError) as error:
            conn.rollback()
            print(error)
        finally:
            conn.close()
    def queryPosition(self, workpiece_id):
        """
        This function is used for making a query for average position and timestamp in 10 seconds resolution values.
        The function returns a dataframe, whose data types have been defined inside of function.
        Input:      - workpiece_id                                        ... Workpiece ID to query for

        Output:     - df                                                  ... Dataframe of the resulting query
        """
        conn = connectTSDB()
        curr = conn.cursor()
        queryPosition = f"SELECT bucket, xabs_avg, yabs_avg, zabs_avg, cabs_avg, aabs_avg FROM contlive_process_3 WHERE workpiece_id = %s;"
        try:
            curr.execute(queryPosition, (workpiece_id,))
            results = curr.fetchall()
            df = pd.DataFrame(results, columns=['bucket', 'xabs_avg', 'yabs_avg', 'zabs_avg', 'cabs_avg', 'aabs_avg'])
            df['bucket'] = df['bucket'].dt.time
            df['bucket'] = df['bucket'].astype(str)
            df['xabs_avg'] = df['xabs_avg'].astype(float)
            df['yabs_avg'] = df['yabs_avg'].astype(float)
            df['zabs_avg'] = df['zabs_avg'].astype(float)
            df['cabs_avg'] = df['cabs_avg'].astype(float)
            df['aabs_avg'] = df['aabs_avg'].astype(float)
            return df
        except(Exception, psycopg2.DatabaseError) as error:
            conn.rollback()
            print(error)
        finally:
            conn.close()
    def querySpindleLoad(self, workpiece_id):
        """
        This function is used for making a query for average spindle load and timestamp in 10 seconds resolution values.
        The function returns a dataframe, whose data types have been defined inside of function.
        Input:      - workpiece_id                                        ... Workpiece ID to query for

        Output:     - df                                                  ... Dataframe of the resulting query
        """
        conn = connectTSDB()
        curr = conn.cursor()
        queryPosition = f"SELECT bucket, spindleload_avg FROM contlive_process_3 WHERE workpiece_id = %s;"
        try:
            curr.execute(queryPosition, (workpiece_id,))
            results = curr.fetchall()
            df = pd.DataFrame(results, columns=['bucket', 'spindleload_avg'])
            df['bucket'] = df['bucket'].dt.time
            df['bucket'] = df['bucket'].astype(str)
            df['spindleload_avg'] = df['spindleload_avg'].astype(float)
            return df
        except(Exception, psycopg2.DatabaseError) as error:
            conn.rollback()
            print(error)
        finally:
            conn.close()

    def querySpindleSpeed(self, workpiece_id):
        """
        This function is used for making a query for average spindle speed and timestamp in 10 seconds resolution values.
        The function returns a dataframe, whose data types have been defined inside of function.
        Input:      - workpiece_id                                        ... Workpiece ID to query for

        Output:     - df                                                  ... Dataframe of the resulting query
        """
        conn = connectTSDB()
        curr = conn.cursor()
        queryPosition = f"SELECT bucket, spindlespeed_avg FROM contlive_process_3 WHERE workpiece_id = %s;"
        try:
            curr.execute(queryPosition, (workpiece_id,))
            results = curr.fetchall()
            df = pd.DataFrame(results, columns=['bucket', 'spindlespeed_avg'])
            df['bucket'] = df['bucket'].dt.time
            df['bucket'] = df['bucket'].astype(str)
            df['spindlespeed_avg'] = df['spindlespeed_avg'].astype(float)
            return df
        except(Exception, psycopg2.DatabaseError) as error:
            conn.rollback()
            print(error)
        finally:
            conn.close()

    def queryFeedRate(self, workpiece_id):
        """
        This function is used for making a query for average feed rate and timestamp in 10 seconds resolution values.
        The function returns a dataframe, whose data types have been defined inside of function.
        Input:      - workpiece_id                                        ... Workpiece ID to query for

        Output:     - df                                                  ... Dataframe of the resulting query
        """
        conn = connectTSDB()
        curr = conn.cursor()
        queryPosition = f"SELECT bucket, feedrate_avg FROM contlive_process_3 WHERE workpiece_id = %s;"
        try:
            curr.execute(queryPosition, (workpiece_id,))
            results = curr.fetchall()
            df = pd.DataFrame(results, columns=['bucket', 'feedrate_avg'])
            df['bucket'] = df['bucket'].dt.time
            df['bucket'] = df['bucket'].astype(str)
            df['feedrate_avg'] = df['feedrate_avg'].astype(float)
            return df
        except(Exception, psycopg2.DatabaseError) as error:
            conn.rollback()
            print(error)
        finally:
            conn.close()

    def queryAcceleration(self, workpiece_id):
        """
        This function is used for making a query for average acceleration and timestamp in 10 seconds resolution values.
        The function returns a dataframe, whose data types have been defined inside of function.
        Input:      - workpiece_id                                        ... Workpiece ID to query for

        Output:     - df                                                  ... Dataframe of the resulting query
        """
        conn = connectTSDB()
        curr = conn.cursor()
        queryAcceleration = f"SELECT bucket, xacc_avg FROM contlive_process_3 WHERE workpiece_id = %s;"
        try:
            curr.execute(queryAcceleration, (workpiece_id,))
            results = curr.fetchall()
            df = pd.DataFrame(results, columns=['bucket', 'xacc_avg'])
            df['bucket'] = df['bucket'].dt.time
            df['bucket'] = df['bucket'].astype(str)
            df['xacc_avg'] = df['xacc_avg'].astype(float)
            return df
        except(Exception, psycopg2.DatabaseError) as error:
            conn.rollback()
            print(error)
        finally:
            conn.close()

    def queryRz(self, inspection_id, filterRz):
        """
        This function is used for making a query for Rz values of certain filter criterium. This filter criterium includes the first three characters of the Experiment ID.
        Input:      - inspection_id                                       ... Inspection ID to query for
                    - filterRz                                            ... First three characters of Experiment ID to query

        Output:     - df                                                  ... Dataframe of the resulting query
        """
        conn = connectTSDB()
        curr = conn.cursor()
        queryRz = f"SELECT CONCAT(experiment_id, '_', window_id), rz FROM rarz WHERE inspection_id = %s AND SUBSTRING(experiment_id FROM 1 FOR 3) = %s;"
        try:
            curr.execute(queryRz, (inspection_id, filterRz))
            results = curr.fetchall()
            df = pd.DataFrame(results, columns=['experiment_window_id', 'rz'])
            return df
        except(Exception, psycopg2.DatabaseError) as error:
            conn.rollback()
            print(error)
        finally:
            conn.close()

    def queryRa(self, inspection_id, filterRa):
        """
        This function is used for making a query for Ra values of certain filter criterium. This filter criterium includes the first three characters of the Experiment ID.
        Input:      - inspection_id                                       ... Inspection ID to query for
                    - filterRa                                            ... First three characters of Experiment ID to query

        Output:     - df                                                  ... Dataframe of the resulting query
        """
        conn = connectTSDB()
        curr = conn.cursor()
        queryRa = f"SELECT CONCAT(experiment_id, '_', window_id), ra FROM rarz WHERE inspection_id = %s AND SUBSTRING(experiment_id FROM 1 FOR 3) = %s;"
        try:
            curr.execute(queryRa, (inspection_id, filterRa))
            results = curr.fetchall()
            df = pd.DataFrame(results, columns=['experiment_window_id', 'ra'])
            return df
        except(Exception, psycopg2.DatabaseError) as error:
            conn.rollback()
            print(error)
        finally:
            conn.close()


#################################################################################################################################################### EXPORT FUNCTIONS

    def exportAcc(self, workpiece_id, process_folder):
        """
        Exports the content of a certain workpiece id from acc_process table as a csv file.
        Input:		- workpiece_id                                        ... workpiece id to query
                    - process_folder                                      ... directory to store exported file

        Output:		- acc_{workpiece_id}.csv in case no error occurs      ... resulting csv file
        """
        conn = connectTSDB()
        curr = conn.cursor()
        queryAcc = f"SELECT * FROM acc_process WHERE workpiece_id = %s;"  # table name can be changed
        output_file = process_folder + f"\\acc_{workpiece_id}.csv"
        try:
            curr.execute(queryAcc, (workpiece_id,))
            results = curr.fetchall()
            with open(output_file, 'w', newline='') as csvfile:
                csv_writer = csv.writer(csvfile)
                csv_writer.writerow([desc[0] for desc in curr.description])
                csv_writer.writerows(results)
            print(f"output for workpiece_id: {workpiece_id} has been generated in {output_dir}.")
        except(Exception, psycopg2.DatabaseError) as error:
            conn.rollback()
            print(error)
        finally:
            conn.close()


    def exportNc(self, workpiece_id, process_folder):
        """
        Exports the content of a certain workpiece id from nc_process table as a csv file.
        Input:		- workpiece_id                                        ... workpiece id to query
                    - process_folder                                      ... directory to store exported file

        Output:		- nc_{workpiece_id}.csv in case no error occurs       ... resulting csv file
        """
        conn = connectTSDB()
        curr = conn.cursor()
        queryNc = f"SELECT * FROM nc_process WHERE workpiece_id = %s;"  # table name can be changed
        output_file = process_folder + f"\\nc_{workpiece_id}.csv"
        try:
            curr.execute(queryNc, (workpiece_id,))
            results = curr.fetchall()
            with open(output_file, 'w', newline='') as csvfile:
                csv_writer = csv.writer(csvfile)
                csv_writer.writerow([desc[0] for desc in curr.description])
                csv_writer.writerows(results)
            print(f"output for workpiece_id: {workpiece_id} has been generated in {output_file}.")
        except(Exception, psycopg2.DatabaseError) as error:
            conn.rollback()
            print(error)
        finally:
            conn.close()


    def exportContinousAggregate(self, workpiece_id, process_folder):
        """
        Exports the content of a certain workpiece id from contlive_process table as a csv file.
        Input:		- workpiece_id                                             ... workpiece id to query
                    - process_folder                                           ... directory to store exported file

        Output:		- contlive_{workpiece_id}.csv in case no error occurs      ... resulting csv file
        """
        conn = connectTSDB()
        curr = conn.cursor()
        queryCont = f"SELECT * FROM contlive_process WHERE workpiece_id = %s;"  # table name can be changed
        output_file = process_folder + f"\\contlive_{workpiece_id}.csv"
        try:
            curr.execute(queryCont, (workpiece_id,))
            results = curr.fetchall()
            with open(output_file, 'w', newline='') as csvfile:
                csv_writer = csv.writer(csvfile)
                csv_writer.writerow([desc[0] for desc in curr.description])
                csv_writer.writerows(results)
            print(f"output for workpiece_id: {workpiece_id} has been generated in {output_file}.")
        except(Exception, psycopg2.DatabaseError) as error:
            conn.rollback()
            print(error)
        finally:
            conn.close()


    def exportManOpt(self, process_id, process_folder):
        """
        Exports the content of a certain process id from manufacturing_operations table as a csv file.
        Input:		- process_id                                              ... process id to query
                    - output_dir                                              ... directory to store exported file

        Output:		- manopt_{workpiece_id}.csv in case no error occurs       ... resulting csv file
        """
        conn = connectTSDB()
        curr = conn.cursor()
        queryAcc = f"SELECT * FROM manufacturing_operations WHERE process_id = %s;"  # table name can be changed
        output_file = process_folder + f"\\manopt_{process_id}.csv"
        try:
            curr.execute(queryAcc, (process_id,))
            results = curr.fetchall()
            with open(output_file, 'w', newline='') as csvfile:
                csv_writer = csv.writer(csvfile)
                csv_writer.writerow([desc[0] for desc in curr.description])
                csv_writer.writerows(results)
            print(f"output for process_id: {process_id} has been generated in {output_file}.")
        except(Exception, psycopg2.DatabaseError) as error:
            conn.rollback()
            print(error)
        finally:
            conn.close()


    def exportQuality(self, inspectionId, quality_folder):
        """
        Creates a folder structure regarding the profile classes and exports for every class related dataset as csv file to corresponding folder.
        Input:		- inspectionId                                                           ... inspection id to export
                    - quality_folder                                                         ... directory to store exported files

        Output:		- {profileClass}_{inspectionId}.csv in case no error occurs              ... resulting csv files
        """
        conn = connectTSDB()
        curr = conn.cursor()

        try:
            queryRarz = f"SELECT DISTINCT ex_code FROM (SELECT LEFT (experiment_id, 3) AS ex_code FROM rarz WHERE inspection_id = %s) AS subquery;"
            profileClasses = []
            curr.execute(queryRarz, (inspectionId,))
            results = curr.fetchall()
            for row in results:
                profileClasses.append(row[0])
                suboutput = os.path.join(quality_folder, str(row[0]))
                os.mkdir(suboutput)
            print("Quality folder structure has been created.")
            for profileClass in profileClasses:
                output_folder = os.path.join(quality_folder, profileClass)
                output_file = output_folder + f"\\{profileClass}_{inspectionId}.csv"
                queryRarz = f"SELECT * FROM rarz WHERE inspection_id = %s AND LEFT (experiment_id, 3) = %s;"
                curr.execute(queryRarz, (inspectionId, str(profileClass)))
                results = curr.fetchall()
                with open(output_file, 'w', newline='') as csvfile:
                    csv_writer = csv.writer(csvfile)
                    csv_writer.writerow([desc[0] for desc in curr.description])
                    csv_writer.writerows(results)
            print("Quality data export has been completed.")
        except(Exception, psycopg2.DatabaseError) as error:
            conn.rollback()
            print(error)
        finally:
            conn.close()
#################################################################################################################################################### DELETE FUNCTIONS
    def dropTable(self, tableName):
        """
        Drops the table with a given name
        Input:		tableName                                     ... table name to drop

        Output:		table has been dropped in case no error occurs
        """
        conn = connectTSDB()
        curr = conn.cursor()
        dropTable = f"""
        DROP TABLE {tableName};

        """
        try:
            curr.execute(dropTable)
            conn.commit()
            time.sleep(2)
            curr.close()
            print(f"Table: {tableName} has been dropped")
        except(Exception, psycopg2.DatabaseError) as error:
            conn.rollback()
            print(error)
        finally:
            conn.close()

    def dropMaterializedView(self, materializedViewName):
        """
        Drops the materialized view with a given name
        Input:		materializedView                             ... table name to drop

        Output:		materialized view has been dropped in case no error occurs
        """
        conn = connectTSDB()
        curr = conn.cursor()
        dropMaterializedView = f"""
        DROP MATERIALIZED VIEW {materializedViewName};

        """
        try:
            curr.execute(dropMaterializedView)
            conn.commit()
            time.sleep(2)
            curr.close()
            print(f"View: {materializedViewName} has been dropped")
        except(Exception, psycopg2.DatabaseError) as error:
            conn.rollback()
            print(error)
        finally:
            conn.close()
